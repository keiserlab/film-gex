{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "module_path = os.path.abspath(os.path.join(os.pardir))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.metrics.sklearns import R2Score\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Custom\n",
    "from project.film_model import LinearBlock, FiLMGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FiLM Structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FiLMNetwork(pl.LightningModule):\n",
    "    def __init__(self, inputs_sz, conds_sz, learning_rate=1e-2, metric=R2Score()):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.metric = metric\n",
    "        self.inputs_emb = LinearBlock(in_sz=inputs_sz, layers=[512,256,128,64], out_sz=32, ps=None, use_bn=True, bn_final=True)\n",
    "        self.conds_emb = LinearBlock(in_sz=conds_sz, layers=[], out_sz=32, ps=None, use_bn=True, bn_final=False)\n",
    "        self.film_1 = FiLMGenerator(in_sz=self.conds_emb.out_sz, layers=[], out_sz=32, ps=None, use_bn=False, bn_final=False)\n",
    "        self.block_1 = LinearBlock(in_sz=self.film_1.out_sz, layers=[16], out_sz=16, ps=None, use_bn=True, bn_final=True)\n",
    "        self.film_2 = FiLMGenerator(in_sz=self.conds_emb.out_sz, layers=[], out_sz=16, ps=None, use_bn=False, bn_final=False)\n",
    "        self.block_2 = LinearBlock(in_sz=self.film_2.out_sz, layers=[8], out_sz=1, ps=None, use_bn=True, bn_final=False)\n",
    "    \n",
    "    def _forward(self, batch, batch_idx):\n",
    "        inputs, conds, y = batch\n",
    "        input_emb = self.inputs_emb(inputs)\n",
    "        conds_emb = self.conds_emb(conds)\n",
    "        gamma_1, beta_1 = self.film_1(conds_emb)\n",
    "        x = input_emb * gamma_1 + beta_1\n",
    "        x = self.block_1(x)\n",
    "        gamma_2, beta_2 = self.film_2(conds_emb)\n",
    "        x = x * gamma_2 + beta_2\n",
    "        y_hat = self.block_2(x)\n",
    "        loss = F.mse_loss(y_hat, y)\n",
    "        return loss\n",
    "    \n",
    "    def forward(self, conds):\n",
    "        return self.conds_emb(conds)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss = self._forward(batch, batch_idx)\n",
    "        result = pl.TrainResult(minimize=loss)\n",
    "        result.log('train_loss', loss)\n",
    "        return result\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss = self._forward(batch, batch_idx)\n",
    "        result = pl.EvalResult(checkpoint_on=loss)\n",
    "        result.log('val_loss', loss, on_step=True)\n",
    "        result.log('val_r2', self.metric(y_hat, y), on_step=True)\n",
    "        return result\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        loss = self._forward(batch, batch_idx)\n",
    "        result = pl.EvalResult(checkpoint_on=loss)\n",
    "        result.log('test_loss', loss, on_step=True)\n",
    "        result.log('test_r2', self.metric(y_hat, y), on_step=True)\n",
    "        return result\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.hparams.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar = FiLMNetwork(978, 513)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FiLMNetwork(\n",
       "  (metric): R2Score()\n",
       "  (inputs_emb): LinearBlock(\n",
       "    (block): Sequential(\n",
       "      (0): Linear(in_features=978, out_features=512, bias=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (4): ReLU(inplace=True)\n",
       "      (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (6): Linear(in_features=256, out_features=128, bias=True)\n",
       "      (7): ReLU(inplace=True)\n",
       "      (8): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (9): Linear(in_features=128, out_features=64, bias=True)\n",
       "      (10): ReLU(inplace=True)\n",
       "      (11): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (12): Linear(in_features=64, out_features=32, bias=True)\n",
       "      (13): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (conds_emb): LinearBlock(\n",
       "    (block): Sequential(\n",
       "      (0): Linear(in_features=513, out_features=32, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (film_1): FiLMGenerator(\n",
       "    (gamma): LinearBlock(\n",
       "      (block): Sequential(\n",
       "        (0): Linear(in_features=32, out_features=32, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (beta): LinearBlock(\n",
       "      (block): Sequential(\n",
       "        (0): Linear(in_features=32, out_features=32, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (block_1): LinearBlock(\n",
       "    (block): Sequential(\n",
       "      (0): Linear(in_features=32, out_features=16, bias=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): Linear(in_features=16, out_features=16, bias=True)\n",
       "      (4): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (film_2): FiLMGenerator(\n",
       "    (gamma): LinearBlock(\n",
       "      (block): Sequential(\n",
       "        (0): Linear(in_features=32, out_features=16, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (beta): LinearBlock(\n",
       "      (block): Sequential(\n",
       "        (0): Linear(in_features=32, out_features=16, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (block_2): LinearBlock(\n",
       "    (block): Sequential(\n",
       "      (0): Linear(in_features=16, out_features=8, bias=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): Linear(in_features=8, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concat Structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "32 * 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "512 / 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConcatNetwork(pl.LightningModule):\n",
    "    def __init__(self, inputs_sz, conds_sz, learning_rate=1e-2, metric=R2Score()):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.metric = metric\n",
    "        self.inputs_emb = LinearBlock(in_sz=inputs_sz, layers=[512,256,128,64], out_sz=32, ps=None, use_bn=True, bn_final=True)\n",
    "        self.conds_emb = LinearBlock(in_sz=conds_sz, layers=[], out_sz=32, ps=None, use_bn=True, bn_final=False)\n",
    "        self.block_1 = LinearBlock(in_sz=self.inputs_emb.out_sz + self.conds_emb.out_sz, layers=[16], out_sz=16, ps=None, use_bn=True, bn_final=True)\n",
    "        self.block_2 = LinearBlock(in_sz=self.block_1.out_sz, layers=[8], out_sz=1, ps=None, use_bn=True, bn_final=False)\n",
    "    \n",
    "    def _forward(self, batch, batch_idx):\n",
    "        inputs, conds, y = batch\n",
    "        input_emb = self.inputs_emb(inputs)\n",
    "        conds_emb = self.conds_emb(conds)\n",
    "        x = torch.cat([input_emb, conds_emb], dim=1)\n",
    "        x = self.block_1(x)\n",
    "        y_hat = self.block_2(x)\n",
    "        loss = F.mse_loss(y_hat, y)\n",
    "        return loss\n",
    "    \n",
    "    def forward(self, conds):\n",
    "        return self.conds_emb(conds)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss = self._forward(batch, batch_idx)\n",
    "        result = pl.TrainResult(minimize=loss)\n",
    "        result.log('train_loss', loss)\n",
    "        return result\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss = self._forward(batch, batch_idx)\n",
    "        result = pl.EvalResult(checkpoint_on=loss)\n",
    "        result.log('val_loss', loss, on_step=True)\n",
    "        result.log('val_r2', self.metric(y_hat, y), on_step=True)\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        loss = self._forward(batch, batch_idx)\n",
    "        result = pl.EvalResult(checkpoint_on=loss)\n",
    "        result.log('test_loss', loss, on_step=True)\n",
    "        result.log('test_r2', self.metric(y_hat, y), on_step=True)\n",
    "        return result\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.hparams.learning_rate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:lightning]",
   "language": "python",
   "name": "conda-env-lightning-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
