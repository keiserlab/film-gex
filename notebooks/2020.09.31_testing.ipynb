{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext tensorboard\n",
    "\n",
    "import sys\n",
    "import os\n",
    "module_path = os.path.abspath(os.path.join(os.pardir))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import Trainer, seed_everything\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "from pytorch_lightning.loggers.tensorboard import TensorBoardLogger\n",
    "\n",
    "from project.datasets import Dataset, CTRPDataModule\n",
    "from project.film_model import FiLMNetwork, ConcatNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "from sklearn import model_selection\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "from pytorch_lightning.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.dataset as ds\n",
    "import pyarrow.feather as feather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ds.dataset(data_path.joinpath(\"train_sub.feather\"), format='feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare(exp, subset=True):\n",
    "    data_path = Path(\"../../film-gex-data/processed/\")\n",
    "    input_cols = joblib.load(data_path.joinpath(\"gene_cols.pkl\"))\n",
    "    \n",
    "    if exp=='id':\n",
    "        cpd_id = \"master_cpd_id\"\n",
    "        cond_cols = np.array([cpd_id, 'cpd_conc_umol'])\n",
    "    else:\n",
    "        fp_cols = joblib.load(data_path.joinpath(\"fp_cols.pkl\"))\n",
    "        cond_cols = np.append(fp_cols, ['cpd_conc_umol'])\n",
    "        \n",
    "    if subset:\n",
    "        dataset = ds.dataset(data_path.joinpath(\"train_sub.feather\"), format='feather')\n",
    "    else:\n",
    "        dataset = ds.dataset(data_path.joinpath(\"train.feather\"), format='feather')\n",
    "        \n",
    "    return dataset, input_cols, cond_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv(name, exp, nfolds, dataset, input_cols, cond_cols, batch_size):\n",
    "    seed_everything(2299)\n",
    "    cols = list(np.concatenate((input_cols, cond_cols, ['cpd_avg_pv'])))\n",
    "    \n",
    "    for fold in np.arange(0,nfolds):\n",
    "        train = dataset.to_table(columns=cols, filter=ds.field('fold') != fold).to_pandas()\n",
    "        val = dataset.to_table(columns=cols, filter=ds.field('fold') == fold).to_pandas()\n",
    "        # DataModule\n",
    "        dm = CTRPDataModule(train,\n",
    "                            val,\n",
    "                            input_cols,\n",
    "                            cond_cols,\n",
    "                            target='cpd_avg_pv',\n",
    "                            batch_size=batch_size)\n",
    "        # Model\n",
    "        if exp=='film':\n",
    "            model = FiLMNetwork(len(input_cols), len(cond_cols))\n",
    "        else:\n",
    "            model = ConcatNetwork(len(input_cols), len(cond_cols))\n",
    "        # Callbacks\n",
    "        logger = TensorBoardLogger(save_dir=os.getcwd(),\n",
    "                                   version=\"{}_{}_fold_{}\".format(name, exp, fold),\n",
    "                                   name='lightning_logs')\n",
    "        early_stop = EarlyStopping(monitor='val_loss',\n",
    "                                   min_delta=0.01)\n",
    "        # Trainer\n",
    "        trainer = Trainer(max_epochs=15, \n",
    "                          gpus=[1,2,3,4,5,6],\n",
    "                          logger=logger,\n",
    "                          early_stop_callback=early_stop,\n",
    "                          distributed_backend='dp')\n",
    "        trainer.fit(model, dm)\n",
    "    return print(\"Completed CV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, input_cols, cond_cols = prepare('id', subset=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'test'\n",
    "exp = 'id'\n",
    "nfolds = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "CUDA_VISIBLE_DEVICES: [1,2,3,4,5,6]\n",
      "/srv/home/wconnell/anaconda3/envs/lightning/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:37: UserWarning: Could not log computational graph since the `model.example_input_array` attribute is not set or `input_array` was not given\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "  | Name       | Type        | Params\n",
      "-------------------------------------------\n",
      "0 | metric     | R2Score     | 0     \n",
      "1 | inputs_emb | LinearBlock | 677 K \n",
      "2 | conds_emb  | LinearBlock | 96    \n",
      "3 | block_1    | LinearBlock | 1 K   \n",
      "4 | block_2    | LinearBlock | 161   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  80%|███████▉  | 1799/2254 [02:49<00:42, 10.60it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  80%|███████▉  | 1799/2254 [03:02<00:46,  9.87it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  80%|███████▉  | 1800/2254 [03:06<00:47,  9.66it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  80%|███████▉  | 1802/2254 [03:06<00:46,  9.66it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  80%|████████  | 1804/2254 [03:06<00:46,  9.66it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  80%|████████  | 1806/2254 [03:06<00:46,  9.67it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  80%|████████  | 1808/2254 [03:06<00:46,  9.67it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  80%|████████  | 1810/2254 [03:07<00:45,  9.67it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  80%|████████  | 1812/2254 [03:07<00:45,  9.68it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  80%|████████  | 1814/2254 [03:07<00:45,  9.68it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  81%|████████  | 1816/2254 [03:07<00:45,  9.68it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  81%|████████  | 1818/2254 [03:07<00:45,  9.69it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  81%|████████  | 1820/2254 [03:07<00:44,  9.69it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  81%|████████  | 1822/2254 [03:07<00:44,  9.69it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  81%|████████  | 1824/2254 [03:08<00:44,  9.70it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  81%|████████  | 1826/2254 [03:08<00:44,  9.70it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  81%|████████  | 1828/2254 [03:08<00:43,  9.71it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  81%|████████  | 1830/2254 [03:08<00:43,  9.71it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  81%|████████▏ | 1832/2254 [03:08<00:43,  9.71it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  81%|████████▏ | 1834/2254 [03:08<00:43,  9.72it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  81%|████████▏ | 1836/2254 [03:08<00:43,  9.72it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  82%|████████▏ | 1838/2254 [03:09<00:42,  9.72it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  82%|████████▏ | 1840/2254 [03:09<00:42,  9.73it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  82%|████████▏ | 1842/2254 [03:09<00:42,  9.73it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  82%|████████▏ | 1844/2254 [03:09<00:42,  9.73it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  82%|████████▏ | 1846/2254 [03:09<00:41,  9.74it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  82%|████████▏ | 1848/2254 [03:09<00:41,  9.74it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  82%|████████▏ | 1850/2254 [03:09<00:41,  9.74it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  82%|████████▏ | 1852/2254 [03:10<00:41,  9.75it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  82%|████████▏ | 1854/2254 [03:10<00:41,  9.75it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  82%|████████▏ | 1856/2254 [03:10<00:40,  9.75it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  82%|████████▏ | 1858/2254 [03:10<00:40,  9.76it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  83%|████████▎ | 1860/2254 [03:10<00:40,  9.76it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  83%|████████▎ | 1862/2254 [03:10<00:40,  9.76it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  83%|████████▎ | 1864/2254 [03:10<00:39,  9.77it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  83%|████████▎ | 1866/2254 [03:10<00:39,  9.77it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  83%|████████▎ | 1868/2254 [03:11<00:39,  9.77it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  83%|████████▎ | 1870/2254 [03:11<00:39,  9.78it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  83%|████████▎ | 1872/2254 [03:11<00:39,  9.78it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  83%|████████▎ | 1874/2254 [03:11<00:38,  9.79it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  83%|████████▎ | 1876/2254 [03:11<00:38,  9.79it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  83%|████████▎ | 1878/2254 [03:11<00:38,  9.79it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  83%|████████▎ | 1880/2254 [03:11<00:38,  9.79it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  83%|████████▎ | 1882/2254 [03:12<00:37,  9.80it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  84%|████████▎ | 1884/2254 [03:12<00:37,  9.80it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  84%|████████▎ | 1886/2254 [03:12<00:37,  9.80it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  84%|████████▍ | 1888/2254 [03:12<00:37,  9.81it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  84%|████████▍ | 1890/2254 [03:12<00:37,  9.81it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  84%|████████▍ | 1892/2254 [03:12<00:36,  9.81it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  84%|████████▍ | 1894/2254 [03:12<00:36,  9.82it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  84%|████████▍ | 1896/2254 [03:13<00:36,  9.82it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  84%|████████▍ | 1898/2254 [03:13<00:36,  9.82it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  84%|████████▍ | 1900/2254 [03:13<00:36,  9.83it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  84%|████████▍ | 1902/2254 [03:13<00:35,  9.83it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  84%|████████▍ | 1904/2254 [03:13<00:35,  9.83it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  85%|████████▍ | 1906/2254 [03:13<00:35,  9.84it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  85%|████████▍ | 1908/2254 [03:13<00:35,  9.84it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  85%|████████▍ | 1910/2254 [03:14<00:34,  9.84it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  85%|████████▍ | 1912/2254 [03:14<00:34,  9.85it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  85%|████████▍ | 1914/2254 [03:14<00:34,  9.85it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  85%|████████▌ | 1916/2254 [03:14<00:34,  9.85it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  85%|████████▌ | 1918/2254 [03:14<00:34,  9.86it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  85%|████████▌ | 1920/2254 [03:14<00:33,  9.86it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  85%|████████▌ | 1922/2254 [03:14<00:33,  9.86it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  85%|████████▌ | 1924/2254 [03:14<00:33,  9.87it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  85%|████████▌ | 1926/2254 [03:15<00:33,  9.87it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  86%|████████▌ | 1928/2254 [03:15<00:33,  9.87it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  86%|████████▌ | 1930/2254 [03:15<00:32,  9.88it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  86%|████████▌ | 1932/2254 [03:15<00:32,  9.88it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  86%|████████▌ | 1934/2254 [03:15<00:32,  9.88it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  86%|████████▌ | 1936/2254 [03:15<00:32,  9.89it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  86%|████████▌ | 1938/2254 [03:15<00:31,  9.89it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  86%|████████▌ | 1940/2254 [03:16<00:31,  9.89it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  86%|████████▌ | 1942/2254 [03:16<00:31,  9.89it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  86%|████████▌ | 1944/2254 [03:16<00:31,  9.90it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  86%|████████▋ | 1946/2254 [03:16<00:31,  9.90it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  86%|████████▋ | 1948/2254 [03:16<00:30,  9.90it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  87%|████████▋ | 1950/2254 [03:16<00:30,  9.91it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  87%|████████▋ | 1952/2254 [03:16<00:30,  9.91it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  87%|████████▋ | 1954/2254 [03:17<00:30,  9.91it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  87%|████████▋ | 1956/2254 [03:17<00:30,  9.92it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  87%|████████▋ | 1958/2254 [03:17<00:29,  9.92it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  87%|████████▋ | 1960/2254 [03:17<00:29,  9.92it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  87%|████████▋ | 1962/2254 [03:17<00:29,  9.93it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  87%|████████▋ | 1964/2254 [03:17<00:29,  9.93it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  87%|████████▋ | 1966/2254 [03:17<00:28,  9.93it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  87%|████████▋ | 1968/2254 [03:18<00:28,  9.94it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  87%|████████▋ | 1970/2254 [03:18<00:28,  9.94it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  87%|████████▋ | 1972/2254 [03:18<00:28,  9.94it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  88%|████████▊ | 1974/2254 [03:18<00:28,  9.95it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  88%|████████▊ | 1976/2254 [03:18<00:27,  9.95it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  88%|████████▊ | 1978/2254 [03:18<00:27,  9.95it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  88%|████████▊ | 1980/2254 [03:18<00:27,  9.96it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  88%|████████▊ | 1982/2254 [03:19<00:27,  9.96it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  88%|████████▊ | 1984/2254 [03:19<00:27,  9.96it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  88%|████████▊ | 1986/2254 [03:19<00:26,  9.97it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  88%|████████▊ | 1988/2254 [03:19<00:26,  9.97it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  88%|████████▊ | 1990/2254 [03:19<00:26,  9.97it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  88%|████████▊ | 1992/2254 [03:19<00:26,  9.97it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  88%|████████▊ | 1994/2254 [03:19<00:26,  9.98it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  89%|████████▊ | 1996/2254 [03:19<00:25,  9.98it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  89%|████████▊ | 1998/2254 [03:20<00:25,  9.98it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  89%|████████▊ | 2000/2254 [03:20<00:25,  9.99it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  89%|████████▉ | 2002/2254 [03:20<00:25,  9.99it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  89%|████████▉ | 2004/2254 [03:20<00:25,  9.99it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  89%|████████▉ | 2006/2254 [03:20<00:24, 10.00it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  89%|████████▉ | 2008/2254 [03:21<00:24,  9.99it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  89%|████████▉ | 2010/2254 [03:21<00:24,  9.99it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  89%|████████▉ | 2012/2254 [03:21<00:24,  9.99it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  89%|████████▉ | 2014/2254 [03:21<00:24, 10.00it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  89%|████████▉ | 2016/2254 [03:21<00:23, 10.00it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  90%|████████▉ | 2018/2254 [03:21<00:23, 10.00it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  90%|████████▉ | 2020/2254 [03:21<00:23, 10.01it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  90%|████████▉ | 2022/2254 [03:22<00:23, 10.01it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  90%|████████▉ | 2024/2254 [03:22<00:22, 10.01it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  90%|████████▉ | 2026/2254 [03:22<00:22, 10.02it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  90%|████████▉ | 2028/2254 [03:22<00:22, 10.02it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  90%|█████████ | 2030/2254 [03:22<00:22, 10.02it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  90%|█████████ | 2032/2254 [03:22<00:22, 10.03it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  90%|█████████ | 2034/2254 [03:22<00:21, 10.03it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  90%|█████████ | 2036/2254 [03:22<00:21, 10.03it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  90%|█████████ | 2038/2254 [03:23<00:21, 10.03it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  91%|█████████ | 2040/2254 [03:23<00:21, 10.04it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  91%|█████████ | 2042/2254 [03:23<00:21, 10.04it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  91%|█████████ | 2044/2254 [03:23<00:20, 10.04it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  91%|█████████ | 2046/2254 [03:23<00:20, 10.05it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  91%|█████████ | 2048/2254 [03:23<00:20, 10.05it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  91%|█████████ | 2050/2254 [03:23<00:20, 10.05it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  91%|█████████ | 2052/2254 [03:24<00:20, 10.06it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  91%|█████████ | 2054/2254 [03:24<00:19, 10.06it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  91%|█████████ | 2056/2254 [03:24<00:19, 10.06it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  91%|█████████▏| 2058/2254 [03:24<00:19, 10.07it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  91%|█████████▏| 2060/2254 [03:24<00:19, 10.07it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  91%|█████████▏| 2062/2254 [03:24<00:19, 10.07it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  92%|█████████▏| 2064/2254 [03:24<00:18, 10.07it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  92%|█████████▏| 2066/2254 [03:25<00:18, 10.08it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  92%|█████████▏| 2068/2254 [03:25<00:18, 10.08it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  92%|█████████▏| 2070/2254 [03:25<00:18, 10.08it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  92%|█████████▏| 2072/2254 [03:25<00:18, 10.09it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  92%|█████████▏| 2074/2254 [03:25<00:17, 10.09it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  92%|█████████▏| 2076/2254 [03:25<00:17, 10.09it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  92%|█████████▏| 2078/2254 [03:25<00:17, 10.10it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  92%|█████████▏| 2080/2254 [03:25<00:17, 10.10it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  92%|█████████▏| 2082/2254 [03:26<00:17, 10.10it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  92%|█████████▏| 2084/2254 [03:26<00:16, 10.10it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  93%|█████████▎| 2086/2254 [03:26<00:16, 10.11it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  93%|█████████▎| 2088/2254 [03:26<00:16, 10.11it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  93%|█████████▎| 2090/2254 [03:26<00:16, 10.11it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  93%|█████████▎| 2092/2254 [03:26<00:16, 10.12it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  93%|█████████▎| 2094/2254 [03:26<00:15, 10.12it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  93%|█████████▎| 2096/2254 [03:27<00:15, 10.12it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  93%|█████████▎| 2098/2254 [03:27<00:15, 10.13it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  93%|█████████▎| 2100/2254 [03:27<00:15, 10.13it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  93%|█████████▎| 2102/2254 [03:27<00:15, 10.13it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  93%|█████████▎| 2104/2254 [03:27<00:14, 10.14it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  93%|█████████▎| 2106/2254 [03:27<00:14, 10.14it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  94%|█████████▎| 2108/2254 [03:27<00:14, 10.14it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  94%|█████████▎| 2110/2254 [03:28<00:14, 10.14it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  94%|█████████▎| 2112/2254 [03:28<00:13, 10.15it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  94%|█████████▍| 2114/2254 [03:28<00:13, 10.15it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  94%|█████████▍| 2116/2254 [03:28<00:13, 10.15it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  94%|█████████▍| 2118/2254 [03:28<00:13, 10.15it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  94%|█████████▍| 2120/2254 [03:28<00:13, 10.16it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  94%|█████████▍| 2122/2254 [03:28<00:12, 10.16it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  94%|█████████▍| 2124/2254 [03:28<00:12, 10.16it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  94%|█████████▍| 2126/2254 [03:29<00:12, 10.17it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  94%|█████████▍| 2128/2254 [03:29<00:12, 10.17it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  94%|█████████▍| 2130/2254 [03:29<00:12, 10.17it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  95%|█████████▍| 2132/2254 [03:29<00:11, 10.17it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  95%|█████████▍| 2134/2254 [03:29<00:11, 10.18it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  95%|█████████▍| 2136/2254 [03:29<00:11, 10.18it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  95%|█████████▍| 2138/2254 [03:29<00:11, 10.18it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  95%|█████████▍| 2140/2254 [03:30<00:11, 10.18it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  95%|█████████▌| 2142/2254 [03:30<00:10, 10.19it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  95%|█████████▌| 2144/2254 [03:30<00:10, 10.19it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  95%|█████████▌| 2146/2254 [03:30<00:10, 10.19it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  95%|█████████▌| 2148/2254 [03:30<00:10, 10.20it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  95%|█████████▌| 2150/2254 [03:30<00:10, 10.20it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  95%|█████████▌| 2152/2254 [03:30<00:09, 10.20it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  96%|█████████▌| 2154/2254 [03:31<00:09, 10.21it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  96%|█████████▌| 2156/2254 [03:31<00:09, 10.21it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  96%|█████████▌| 2158/2254 [03:31<00:09, 10.21it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  96%|█████████▌| 2160/2254 [03:31<00:09, 10.21it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  96%|█████████▌| 2162/2254 [03:31<00:09, 10.22it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  96%|█████████▌| 2164/2254 [03:31<00:08, 10.22it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  96%|█████████▌| 2166/2254 [03:31<00:08, 10.22it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  96%|█████████▌| 2168/2254 [03:32<00:08, 10.23it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  96%|█████████▋| 2170/2254 [03:32<00:08, 10.23it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  96%|█████████▋| 2172/2254 [03:32<00:08, 10.23it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  96%|█████████▋| 2174/2254 [03:32<00:07, 10.23it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  97%|█████████▋| 2176/2254 [03:32<00:07, 10.24it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  97%|█████████▋| 2178/2254 [03:32<00:07, 10.24it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  97%|█████████▋| 2180/2254 [03:32<00:07, 10.24it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  97%|█████████▋| 2182/2254 [03:32<00:07, 10.24it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  97%|█████████▋| 2184/2254 [03:33<00:06, 10.25it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  97%|█████████▋| 2186/2254 [03:33<00:06, 10.25it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  97%|█████████▋| 2188/2254 [03:33<00:06, 10.25it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  97%|█████████▋| 2190/2254 [03:33<00:06, 10.26it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  97%|█████████▋| 2192/2254 [03:33<00:06, 10.26it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  97%|█████████▋| 2194/2254 [03:33<00:05, 10.26it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  97%|█████████▋| 2196/2254 [03:33<00:05, 10.26it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  98%|█████████▊| 2198/2254 [03:34<00:05, 10.27it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  98%|█████████▊| 2200/2254 [03:34<00:05, 10.27it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  98%|█████████▊| 2202/2254 [03:34<00:05, 10.27it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  98%|█████████▊| 2204/2254 [03:34<00:04, 10.28it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  98%|█████████▊| 2206/2254 [03:34<00:04, 10.28it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  98%|█████████▊| 2208/2254 [03:34<00:04, 10.28it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  98%|█████████▊| 2210/2254 [03:34<00:04, 10.28it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  98%|█████████▊| 2212/2254 [03:35<00:04, 10.29it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  98%|█████████▊| 2214/2254 [03:35<00:03, 10.29it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  98%|█████████▊| 2216/2254 [03:35<00:03, 10.29it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  98%|█████████▊| 2218/2254 [03:35<00:03, 10.29it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  98%|█████████▊| 2220/2254 [03:35<00:03, 10.30it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  99%|█████████▊| 2222/2254 [03:35<00:03, 10.30it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  99%|█████████▊| 2224/2254 [03:35<00:02, 10.30it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  99%|█████████▉| 2226/2254 [03:36<00:02, 10.31it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  99%|█████████▉| 2228/2254 [03:36<00:02, 10.31it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  99%|█████████▉| 2230/2254 [03:36<00:02, 10.31it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  99%|█████████▉| 2232/2254 [03:36<00:02, 10.31it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  99%|█████████▉| 2234/2254 [03:36<00:01, 10.32it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  99%|█████████▉| 2236/2254 [03:36<00:01, 10.32it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  99%|█████████▉| 2238/2254 [03:36<00:01, 10.32it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  99%|█████████▉| 2240/2254 [03:36<00:01, 10.33it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0:  99%|█████████▉| 2242/2254 [03:37<00:01, 10.33it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0: 100%|█████████▉| 2244/2254 [03:37<00:00, 10.33it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0: 100%|█████████▉| 2246/2254 [03:37<00:00, 10.34it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0: 100%|█████████▉| 2248/2254 [03:37<00:00, 10.34it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0: 100%|█████████▉| 2250/2254 [03:37<00:00, 10.34it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0: 100%|█████████▉| 2252/2254 [03:37<00:00, 10.35it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 0: 100%|██████████| 2254/2254 [03:39<00:00, 10.27it/s, loss=0.093, v_num=ld_0]\n",
      "Epoch 1:  32%|███▏      | 720/2254 [01:15<02:41,  9.50it/s, loss=0.092, v_num=ld_0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fe6a2e00670>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/home/wconnell/anaconda3/envs/lightning/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/srv/home/wconnell/anaconda3/envs/lightning/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 929, in _shutdown_workers\n",
      "    self._pin_memory_thread.join()\n",
      "  File \"/srv/home/wconnell/anaconda3/envs/lightning/lib/python3.8/threading.py\", line 1011, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/srv/home/wconnell/anaconda3/envs/lightning/lib/python3.8/threading.py\", line 1027, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "KeyboardInterrupt: \n",
      "/srv/home/wconnell/anaconda3/envs/lightning/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:37: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Saving latest checkpoint..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  32%|███▏      | 720/2254 [01:16<02:43,  9.40it/s, loss=0.092, v_num=ld_0]\n",
      "Completed CV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-13539:\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/home/wconnell/anaconda3/envs/lightning/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/srv/home/wconnell/anaconda3/envs/lightning/lib/python3.8/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/srv/home/wconnell/anaconda3/envs/lightning/lib/python3.8/site-packages/torch/utils/data/_utils/pin_memory.py\", line 25, in _pin_memory_loop\n",
      "    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/srv/home/wconnell/anaconda3/envs/lightning/lib/python3.8/multiprocessing/queues.py\", line 116, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/srv/home/wconnell/anaconda3/envs/lightning/lib/python3.8/site-packages/torch/multiprocessing/reductions.py\", line 294, in rebuild_storage_fd\n",
      "    fd = df.detach()\n",
      "  File \"/srv/home/wconnell/anaconda3/envs/lightning/lib/python3.8/multiprocessing/resource_sharer.py\", line 58, in detach\n",
      "    return reduction.recv_handle(conn)\n",
      "  File \"/srv/home/wconnell/anaconda3/envs/lightning/lib/python3.8/multiprocessing/reduction.py\", line 189, in recv_handle\n",
      "    return recvfds(s, 1)[0]\n",
      "  File \"/srv/home/wconnell/anaconda3/envs/lightning/lib/python3.8/multiprocessing/reduction.py\", line 157, in recvfds\n",
      "    msg, ancdata, flags, addr = sock.recvmsg(1, socket.CMSG_SPACE(bytes_size))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n"
     ]
    }
   ],
   "source": [
    "cv(name, exp, nfolds, dataset, input_cols, cond_cols, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-e8f0af15c98d26cf\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-e8f0af15c98d26cf\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 9066;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir ./lightning_logs --port 9066"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/srv/home/wconnell/github/film-gex/notebooks'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.default_root_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -5.2721,  -5.0805,   1.7124,  ...,  -5.4074,   1.7200, -13.4092],\n",
       "        [ -0.8518,   0.4557,  -1.1743,  ...,   0.7598,   1.3746,  -2.2434],\n",
       "        [ -1.5418,   1.0390,  -1.1317,  ...,   1.3517,   2.7206,  -1.4814],\n",
       "        ...,\n",
       "        [ -1.4564,   1.6760,   0.2275,  ...,   1.7220,   1.8293,  -1.2928],\n",
       "        [ -2.3295,  -1.4681,  -0.4503,  ...,  -2.5142,   2.1346,  -8.3439],\n",
       "        [ -2.1074,  -1.6664,   0.6190,  ...,  -1.4646,   1.0616,  -6.0193]],\n",
       "       grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo = torch.FloatTensor(val[cond_cols].to_numpy())\n",
    "model.forward(foo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57676, 1502)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11474, 1502)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['fold']==0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.41015625"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "11474 / 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:lightning]",
   "language": "python",
   "name": "conda-env-lightning-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
