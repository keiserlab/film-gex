{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, input_cols, cond_cols, target):\n",
    "        self.inputs = torch.FloatTensor(data[input_cols].to_numpy())\n",
    "        self.conds = torch.FloatTensor(dadta[cond_cols].to_numpy())\n",
    "        self.target = torch.FloatTensor(data[target].to_numpy())\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        return self.inputs[i], self.conds[i], self.target[i]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CTRPDataModule(pl.LightningDataModule):\n",
    "\n",
    "    def __init__(self, train, val, fold, input_cols, cond_cols, target, batch_size=32):\n",
    "        super().__init__()\n",
    "        self.train = train\n",
    "        self.val = val\n",
    "        self.fold = fold\n",
    "        self.input_cols = input_cols\n",
    "        self.cond_cols = cond_cols\n",
    "        self.target = target\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    # When doing distributed training, Datamodules have two optional arguments for\n",
    "    # granular control over download/prepare/splitting data:\n",
    "    def prepare_data(self):\n",
    "        pass\n",
    "\n",
    "    # OPTIONAL, called for every GPU/machine (assigning state is OK)\n",
    "    def setup(self, stage):\n",
    "        # transformations\n",
    "        self.scaler = StandardScaler()\n",
    "        self.train[self.input_cols] = self.scaler.fit_transform(self.train[self.input_cols])\n",
    "        self.val[self.input_cols] = self.scaler.transform(self.val[self.input_cols])\n",
    "        \n",
    "        if stage == 'fit':\n",
    "            self.train_dataset = Dataset(self.train, self.input_cols, self.cond_cols, self.target)\n",
    "            self.val_dataset = Dataset(self.val, self.input_cols, self.cond_cols, self.target)\n",
    "            return self.train_dataset, self.val_dataset\n",
    "        if stage == 'test':\n",
    "            self.test_dataset = Dataset(self.test, self.input_cols, self.cond_cols, self.target)\n",
    "            return self.test_dataset\n",
    "\n",
    "    # return the dataloader for each split\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, num_workers=8, pin_memory=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=self.batch_size)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=self.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"../../film-gex-data/processed/\")\n",
    "input_cols = joblib.load(data_path.joinpath(\"input_cols.pkl\"))\n",
    "cond_cols = joblib.load(data_path.joinpath(\"cond_cols.pkl\"))\n",
    "data = pd.read_pickle(data_path.joinpath(\"train_sub.pkl.gz\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 5\n",
    "target = \"cpd_avg_pv\"\n",
    "group = \"stripped_cell_line_name\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "split() got an unexpected keyword argument 'random_state'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-9a5d59a3dee8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mgkf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_selection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGroupKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mfold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_idx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgkf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: split() got an unexpected keyword argument 'random_state'"
     ]
    }
   ],
   "source": [
    "gkf = model_selection.GroupKFold(n_splits=n_splits, random_state=42)\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(gkf.split(X=data, y=data[target].to_numpy(), groups=data[group].to_numpy())):\n",
    "    train = data.iloc[train_idx]\n",
    "    val = data.iloc[val_idx]\n",
    "    \n",
    "    dm = CTRPDataModule(train,\n",
    "                        val,\n",
    "                        fold,\n",
    "                        input_cols,\n",
    "                        cond_cols,\n",
    "                        target=target,\n",
    "                        batch_size=128)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:lightning]",
   "language": "python",
   "name": "conda-env-lightning-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
