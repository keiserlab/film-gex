{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CTRPDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, features, target):\n",
    "        self.features = torch.FloatTensor(data[features].to_numpy())\n",
    "        self.target = torch.FloatTensor(data[target].to_numpy())\n",
    "        self.fold = torch.Tensor(data['fold'].to_numpy())\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        return self.features[i], self.target[i]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloaders(dataset, fold):\n",
    "    val_idx = torch.where(dataset.fold==fold)[0]\n",
    "    train_loader = torch.utils.data.DataLoader(dataset[~val_idx])\n",
    "    val_loader = torch.utils.data.DataLoader(dataset[val_idx])\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"../../film-gex-data/processed/\")\n",
    "input_cols = joblib.load(data_path.joinpath(\"input_cols.pkl\"))\n",
    "cond_cols = joblib.load(data_path.joinpath(\"cond_cols.pkl\"))\n",
    "data = pd.read_pickle(data_path.joinpath(\"train_sub.pkl.gz\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dataset = CTRPDataset(data, input_cols, 'cpd_avg_pv')\n",
    "cond_dataset = CTRPDataset(data, cond_cols, 'cpd_avg_pv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo, bar = create_dataloaders(input_dataset, fold=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CTRPDataModule(pl.LightningDataModule):\n",
    "\n",
    "    def __init__(self, path, target, val_fold, test_fold, batch_size=32):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.path = Path(path)\n",
    "        self.target = target\n",
    "        self.val_fold = val_fold\n",
    "        self.test_fold = test_fold\n",
    "\n",
    "    # When doing distributed training, Datamodules have two optional arguments for\n",
    "    # granular control over download/prepare/splitting data:\n",
    "    def prepare_data(self):\n",
    "        pass\n",
    "\n",
    "    # OPTIONAL, called for every GPU/machine (assigning state is OK)\n",
    "    def setup(self, stage):\n",
    "        # read data\n",
    "        self.data = pd.read_pickle(self.path.joinpath(\"train_sub.pkl.gz\"))\n",
    "        self.input_cols = joblib.load(self.path.joinpath(\"input_cols.pkl\"))\n",
    "        self.cond_cols = joblib.load(self.path.joinpath(\"cond_cols.pkl\"))\n",
    "        # idx\n",
    "        self.train_idx = np.where((self.data['fold']!=self.val_fold) & (self.data['fold']!=self.test_fold))[0]\n",
    "        self.val_idx = np.where(self.data==self.val_fold)[0]\n",
    "        self.test_idx = np.where(self.data==self.test_fold)[0]\n",
    "        # transform inputs\n",
    "        self.scaler = StandardScaler()\n",
    "        input_train_data = self.scaler.fit_transform(self.data.iloc[self.train_idx][self.input_cols])\n",
    "        input_val_data = self.scaler.transform(self.data.iloc[self.val_idx][self.input_cols])\n",
    "        input_test_data = self.scaler.transform(self.data.iloc[self.test_idx][self.input_cols])\n",
    "        \n",
    "        if stage == 'fit':\n",
    "            self.train_dataset = CTRPDataset(input_train_data, \n",
    "                                             self.data.iloc[self.train_idx][self.cond_cols].to_numpy(),\n",
    "                                             self.data.iloc[self.train_idx][self.target].to_numpy())\n",
    "            self.val_dataset = CTRPDataset(input_val_data,\n",
    "                                           self.data.iloc[self.val_idx][self.cond_cols].to_numpy(),\n",
    "                                           self.data.iloc[self.val_idx][self.target].to_numpy())\n",
    "            return self.train_dataset, self.val_dataset\n",
    "        if stage == 'test':\n",
    "            self.test_dataset = CTRPDataset(input_test_data,\n",
    "                                            self.data.iloc[self.test_idx][self.cond_cols].to_numpy(),\n",
    "                                            self.data.iloc[self.test_idx][self.target].to_numpy())\n",
    "            return self.test_dataset\n",
    "\n",
    "    # return the dataloader for each split\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=self.batch_size)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=self.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = CTRPDataModule(path=\"../../film-gex-data/processed/\",\n",
    "                     target='cpd_avg_pv',\n",
    "                     val_fold=1,\n",
    "                     test_fold=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<__main__.CTRPDataset at 0x7feab73e1730>,\n",
       " <__main__.CTRPDataset at 0x7feab73e1ac0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo.setup(stage='fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.CTRPDataset at 0x7feab73e17c0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo.setup(stage='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset\n",
    "# get train/val idx for gks\n",
    "# create datamodule, transform (norm), to tensor\n",
    "# ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:lightning]",
   "language": "python",
   "name": "conda-env-lightning-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
